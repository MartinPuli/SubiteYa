# üéôÔ∏è Voice Narration Feature - ElevenLabs Integration

## Descripci√≥n General

Esta funcionalidad permite agregar **narraci√≥n de voz profesional con IA** a tus videos usando **ElevenLabs**. La voz narradora puede:

- üåç **Traducir** el contenido del video a cualquier idioma
- üé¨ **Narrar** con estilo profesional (tipo National Geographic)
- üó£Ô∏è **Usar voces personalizadas** o clonadas del usuario
- üéöÔ∏è **Ajustar vol√∫menes** autom√°ticamente entre voz narrador y audio original

## C√≥mo Funciona

### Flujo Autom√°tico

1. **Transcripci√≥n**: El audio del video se extrae y transcribe con Whisper AI
2. **Traducci√≥n**: El contenido se traduce al idioma seleccionado con GPT-4
3. **Generaci√≥n de Script**: Se crea un guion profesional seg√∫n el estilo elegido
4. **S√≠ntesis de Voz**: ElevenLabs genera la narraci√≥n con la voz seleccionada
5. **Mezcla de Audio**: FFmpeg combina la voz con el video, ajustando vol√∫menes

### Estilos de Narraci√≥n Disponibles

- **üé¨ Documental (National Geographic)**: Voz grave y autorizada, perfecta para naturaleza y viajes
- **üìö Educativo**: Tono claro y explicativo, ideal para tutoriales
- **üì∞ Noticias**: Voz profesional y neutral, similar a noticieros
- **üìñ Narrativo**: Narraci√≥n emotiva, perfecta para historias
- **üòä Casual**: Tono conversacional y amigable, ideal para vlogs
- **üíº Profesional**: Voz seria y confiable, corporativo

## Configuraci√≥n

### 1. Obtener API Key de ElevenLabs

1. Crea una cuenta en [ElevenLabs](https://elevenlabs.io/)
2. Ve a tu perfil ‚Üí API Keys
3. Copia tu API key

### 2. Configurar Variables de Entorno

Agrega tu API key al archivo `.env` del backend:

```env
ELEVENLABS_API_KEY=tu_api_key_aqui
```

### 3. Actualizar Base de Datos

Ejecuta la migraci√≥n de Prisma para agregar los nuevos campos:

```bash
cd packages/api
npx prisma migrate dev --name add_voice_narration
```

## Uso en la Interfaz

### Crear Patr√≥n con Narraci√≥n

1. Ve a **Patrones** ‚Üí **Nuevo Patr√≥n**
2. Configura logo, efectos, etc. como siempre
3. Ve a la pesta√±a **"üéôÔ∏è Voz IA"**
4. Activa **"Habilitar Narraci√≥n con IA"**
5. Configura:
   - **Idioma**: Espa√±ol, Ingl√©s, Portugu√©s, etc.
   - **Voz**: Selecciona de las voces disponibles de ElevenLabs
   - **Estilo**: Documentary, Educational, News, etc.
   - **Volumen de Narraci√≥n**: 0-100%
   - **Velocidad**: 0.5x - 2.0x
   - **Volumen de Audio Original**: 0-100% (recomendado: 30%)
6. Guarda el patr√≥n

### Subir Video con Narraci√≥n

1. Ve a **Subir Video**
2. Selecciona tus archivos de video
3. **Selecciona el patr√≥n** que tiene narraci√≥n habilitada
4. Selecciona las cuentas donde publicar
5. Click en **"Subir Videos"**

El sistema autom√°ticamente:

- Procesar√° el video
- Generar√° la narraci√≥n
- Mezclar√° el audio
- Publicar√° en las plataformas seleccionadas

## API Endpoints

### Listar Voces Disponibles

```http
GET /api/elevenlabs/voices
Authorization: Bearer {token}
```

Respuesta:

```json
{
  "voices": [
    {
      "voice_id": "21m00Tcm4TlvDq8ikWAM",
      "name": "Rachel",
      "category": "premade"
    }
  ]
}
```

### Clonar Voz del Usuario

```http
POST /api/elevenlabs/clone
Authorization: Bearer {token}
Content-Type: multipart/form-data

{
  "name": "Mi Voz",
  "description": "Voz clonada para narraci√≥n",
  "files": [audio1.mp3, audio2.mp3]
}
```

### Generar Audio de Prueba

```http
POST /api/elevenlabs/generate
Authorization: Bearer {token}
Content-Type: application/json

{
  "text": "Texto a narrar",
  "voice_id": "21m00Tcm4TlvDq8ikWAM",
  "model_id": "eleven_multilingual_v2"
}
```

## Schema de Base de Datos

Nuevos campos en `BrandPattern`:

```prisma
model BrandPattern {
  // ... campos existentes ...

  // Voice Narration (ElevenLabs)
  enable_voice_narration Boolean  @default(false)
  narration_language     String?  // 'es', 'en', 'pt', 'fr', etc.
  narration_voice_id     String?  // ElevenLabs voice ID
  narration_style        String?  // 'documentary', 'educational', etc.
  narration_volume       Int      @default(80)   // 0-100
  narration_speed        Float    @default(1.0)  // 0.5-2.0
  original_audio_volume  Int      @default(30)   // 0-100
}
```

## Arquitectura de Procesamiento

### Worker de Edici√≥n (`edit-worker-bullmq.ts`)

El worker detecta si un patr√≥n tiene narraci√≥n habilitada:

```typescript
if (pattern.enable_voice_narration) {
  // 1. Extraer audio del video
  const audioPath = await extractAudio(videoPath);

  // 2. Transcribir con Whisper
  const transcription = await whisperTranscribe(audioPath);

  // 3. Traducir y generar script con GPT-4
  const script = await generateNarrationScript(
    transcription,
    pattern.narration_language,
    pattern.narration_style
  );

  // 4. Generar voz con ElevenLabs
  const narrationAudio = await elevenlabs.generateSpeech({
    text: script,
    voice_id: pattern.narration_voice_id,
    voice_settings: {
      stability: 0.5,
      similarity_boost: 0.75,
    },
  });

  // 5. Mezclar audios con FFmpeg
  await mixAudioWithVideo(
    videoPath,
    narrationAudio,
    pattern.narration_volume,
    pattern.original_audio_volume
  );
}
```

## Costos y L√≠mites

### ElevenLabs Pricing

- **Free Tier**: 10,000 caracteres/mes
- **Starter**: $5/mes - 30,000 caracteres
- **Creator**: $22/mes - 100,000 caracteres
- **Pro**: $99/mes - 500,000 caracteres

### Optimizaci√≥n de Uso

- Los scripts se generan de forma concisa
- Se usa el modelo multilingual v2 (mejor calidad/costo)
- Se cachean voces clonadas para reutilizar

## Mejores Pr√°cticas

### Para Mejores Resultados

1. **Usa videos con contenido claro**: Mejor audio original = mejor transcripci√≥n
2. **Define bien el estilo**: Cada estilo genera diferentes tipos de guiones
3. **Ajusta el volumen del audio original**: Recomendado 20-30% cuando hay narraci√≥n
4. **Prueba diferentes voces**: Cada voz tiene caracter√≠sticas √∫nicas
5. **Velocidad de narraci√≥n**: 1.0x es lo m√°s natural, ajusta solo si es necesario

### Debugging

Si la narraci√≥n no se genera:

1. Verifica que `ELEVENLABS_API_KEY` est√© configurada
2. Revisa los logs del worker: `docker logs subiteya-edit-worker`
3. Verifica que Whisper est√© funcionando
4. Comprueba que el patr√≥n tenga `enable_voice_narration = true`

## Roadmap

- [ ] Soporte para m√∫ltiples narradores (di√°logo)
- [ ] Ajuste autom√°tico de timing de la narraci√≥n con el video
- [ ] Efectos de audio (reverb, equalizer)
- [ ] Previsualizaci√≥n de narraci√≥n antes de procesar
- [ ] Clonaci√≥n de voz directamente desde la interfaz
- [ ] Soporte para m√°s idiomas (√°rabe, ruso, turco)

## Contribuir

Para agregar nuevos estilos de narraci√≥n:

1. Edita `PatternEditorPage.tsx` ‚Üí secci√≥n de estilos
2. Agrega el nuevo estilo al array de opciones
3. Crea el prompt correspondiente en el worker
4. Actualiza esta documentaci√≥n

## Soporte

Si tienes problemas:

1. Revisa los logs del backend
2. Verifica la configuraci√≥n de ElevenLabs
3. Abre un issue en GitHub con:
   - Descripci√≥n del problema
   - Logs del worker
   - Configuraci√≥n del patr√≥n utilizado

---

**Desarrollado con ‚ù§Ô∏è por el equipo de SubiteYa**
